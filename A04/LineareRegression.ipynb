{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20dac8d8",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <IMG SRC=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/d5/Fachhochschule_Südwestfalen_20xx_logo.svg/320px-Fachhochschule_Südwestfalen_20xx_logo.svg.png\" WIDTH=250 ALIGN=\"right\">\n",
    "</figure>\n",
    "\n",
    "# Einführung Machine Learning\n",
    "### Sommersemester 2022\n",
    "Prof. Dr. Heiner Giefers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lineare Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der einfachste Fall der Lineraen Regression ist die Vorhersage einer (*abhängigen*) Variablen durch **eine** *unabhängige* Variable.\n",
    "Dieser Spezialfall wird daher auch *einfache Lineare Regression* (ELR) oder *univariate Lineare Regression* genannt.\n",
    "\n",
    "Wir wollen die ELR an einem einfachen Datensatz erproben.\n",
    "Dazu generieren wir uns $N=30$ Datenpunkte im Bereich $x\\in[0,10]$.\n",
    "Die $y$-Werte sollen grob entlang einer geraden liegen.\n",
    "Wir wählen für die gerade eine Steigung von $2$ und den Achsenabschnitt $-5$.\n",
    "\n",
    "Natürlich sollen die Punkte nicht alle **auf** dieser Geraden liegen.\n",
    "Daher fügen wir noch einen kleinen *Störfaktor* ein.\n",
    "Wir addieren zu jedem $y$-Wert einen Wert aus dem Bereich $[-1,1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "N = 30\n",
    "x = 10 * np.random.rand(N)\n",
    "y = 2 * x - 5 + 2*np.random.randn(N)\n",
    "plt.scatter(x, y);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir können nun die *Scikit-Learn* Klasse `LinearRegression` verwenden, um ein ELR Modell für den Datensatz aufzustellen.\n",
    "Mit der `fit`-Methode passen wir das Modell an den Datensatz an.\n",
    "\n",
    "*Hinweis:* Die `fit`-MEthode erwartet ein 2-dimensionales Feld als ersten Parameter. Unser `x` ist aber ein eindimensionales Array. Wir ändern daher mit der `reshape`-Methode die Dimension von `x` vor dem Aufruf von `fit` um."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "x = x.reshape((-1,1))\n",
    "model.fit(x, y)\n",
    "\n",
    "print(\"Steigung:       \", model.coef_[0])\n",
    "print(\"Achsenabschnitt:\", model.intercept_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir können nun die Modellfunktion plotten indem wir zunächst einige neue Datenpunkte erzeugen (`xplot`) und für diese Punkte den $y$-Wert über die `predict`-Methode schätzen.\n",
    "\n",
    "Wir sehen, dass die Gerade die blauen Datenpukte unseres Trainingsdatensatzes sehr gut generalisiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xplot = np.linspace(0, 10, 20).reshape((-1,1))\n",
    "yplot = model.predict(xplot)\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.plot(xplot, yplot, c='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der ``LinearRegression`` Schätzer kann nicht nur auf univariate Probleme angewendet werden, sondern er funktioniert auch für mehrere unabhängige Variable.\n",
    "Die Modellfunktion einer allgemeinen (*multivariaten*) lineren Regression lautet:\n",
    "$$\n",
    "\\hat{y} = a_0 + a_1 x_1 + a_2 x_2 + \\cdots + a_n x_n\n",
    "$$\n",
    "\n",
    "Dabei sind die $x_i$ die einzelnen unabhängigen Variablen, die Werte $a_i$ sind die zu trainierenden Modellparameter.\n",
    "Der Parameter $a_0$, den wir beim univariaten Modell *Achsenabschnitt* genannt haben, heißt auch *Bias*-Parameter.\n",
    "Es ist der einzige Parameter, der unabhängig von den Variablen ins Modell eingeht.\n",
    "\n",
    "$\\hat{y}$ ist der geschätzte Wert der Zielvariablen für den Vektor $\\textbf{x}$.\n",
    "Für unsere Trainingsdaten kennen wir den jeweiligen exakten Wert $y$.\n",
    "Über einen Vergleich von $\\hat{y}$ und $y$ kann man feststellen, wie *gut* die Schaätzung der Modellfunktion ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "N = 30\n",
    "X = 10 * np.random.rand(N, 3)\n",
    "noise = np.random.normal(0, 0.5, (N,3))\n",
    "y = 0.5 + np.dot(X+noise, [1.5, -2., 1.]) + 0.5*np.random.randn(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(15,8))\n",
    "axs[0].scatter(X[:,0], y)\n",
    "axs[1].scatter(X[:,2], y)\n",
    "axs[2].scatter(X[:,1], y)\n",
    "axs[0].set_ylabel('y')\n",
    "axs[0].set_xlabel(r'$x_0$')\n",
    "axs[1].set_xlabel(r'$x_1$')\n",
    "axs[2].set_xlabel(r'$x_2$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe:** Trainieren Sie ein `LinearRegression` Modell mit dem Datensatz `X` und geben Sie die gelerneten Modellparameter $a_0$ bis $a_3$ aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-4c42dc3a5700797b",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preisvorhersage für Häuser in Boston\n",
    "\n",
    "Im folgenden Beispiel verwenden wir einen sehr verbreitet verwendeten Datensatz für die Demonstration von Regressions-Aufgaben, den *Boston Housing Prices*. \n",
    "Die Daten wurden 1978 gesammelt und jeder der 506 Einträge enthält Informationen zu 14 Merkmalen von Häusern aus verschiedenen Vororten in Boston."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "dataset = load_boston()\n",
    "df = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Datensatz enthält folgende Merkmale:\n",
    "- Kriminalitätsrate pro Kopf (crim)\n",
    "- Anteil des Wohnlandes über 25.000 sq.ft (zn)\n",
    "- Anteil der Nicht-Handels-Geschäftsfläche (indus)\n",
    "- Flusslage am Chas River (chas: 1=am Fluss, 0=nicht am Fluss)\n",
    "- Konzentration der Stickstoffoxide (Teile pro 10 Millionen, nox)\n",
    "- durchschnittliche Anzahl Zimmer pro Wohnung (rm)\n",
    "- Anteil der Eigentumswohnungen, die vor 1940 gebaut wurden (age; der Datensatz wurde 1978 veröffentlicht)\n",
    "- gewichtete Entfernung zu fünf Bostoner Beschäftigungszentren (dis)\n",
    "- Index der Zugänglichkeit zu Einfallstraßen (rad)\n",
    "- vollwertiger Immobilien-Steuersatz pro $10.000 (tax)\n",
    "- Schüler-Lehrer-Quotient (ptratio)\n",
    "- Anteil Farbiger: (black; Formel: 1000(Bk – 0.63)²)\n",
    "- Bevölkerungsanteil mit niedrigem Status (lstat)\n",
    "\n",
    "Die Zielvariable `target` ist der Preis der jeweiligen Häuser in Tausend US-Dollar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preise = dataset.target\n",
    "print(f\"Der Wert der Häuser reicht von {int(np.min(preise)*1000)} bis {int(np.max(preise)*1000)} USD\")\n",
    "print(f\"Im Mittel kosten die Häuser {int(np.mean(preise)*1000)} USD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe:** In der folgenden Code-Zelle teilen wir den Datensatz auf, in einen Trainings- und in einen Testdatensatz.\n",
    "Verwenden Sie die Trainingsdaten, um ein lineares Regressionsmodell zu trainieren.\n",
    "Berechnen Sie damit eine Schätzung `y_vorhersage` für die Testdaten.\n",
    "Danach berechnen wird den *mittleren absoluten Fehler* und überprüfen damit, wie gut unser Modell die Preise der Häuser schätzen kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-42d6643b64c7304d",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset.data, dataset.target, test_size=0.3, random_state=42)\n",
    "\n",
    "y_vorhersage = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "mittlerer_fehler = np.sum(np.abs(y_vorhersage-y_test))/len(y_vorhersage)\n",
    "print(f\"Der mittlere Fehler der Vorhersage liegt bei {int(mittlerer_fehler*1000)} USD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## California Housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "dataset = fetch_california_housing()\n",
    "df = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Der Datensatz enthält folgende Merkmale:\n",
    "- Kriminalitätsrate pro Kopf (crim)\n",
    "- Anteil des Wohnlandes über 25.000 sq.ft (zn)\n",
    "- Anteil der Nicht-Handels-Geschäftsfläche (indus)\n",
    "- Flusslage am Chas River (chas: 1=am Fluss, 0=nicht am Fluss)\n",
    "- Konzentration der Stickstoffoxide (Teile pro 10 Millionen, nox)\n",
    "- durchschnittliche Anzahl Zimmer pro Wohnung (rm)\n",
    "- Anteil der Eigentumswohnungen, die vor 1940 gebaut wurden (age; der Datensatz wurde 1978 veröffentlicht)\n",
    "- gewichtete Entfernung zu fünf Bostoner Beschäftigungszentren (dis)\n",
    "- Index der Zugänglichkeit zu Einfallstraßen (rad)\n",
    "- vollwertiger Immobilien-Steuersatz pro $10.000 (tax)\n",
    "- Schüler-Lehrer-Quotient (ptratio)\n",
    "- Anteil Farbiger: (black; Formel: 1000(Bk – 0.63)²)\n",
    "- Bevölkerungsanteil mit niedrigem Status (lstat)\n",
    "\n",
    "Die Zielvariable `target` ist der Preis der jeweiligen Häuser in Tausend US-Dollar\n",
    "\n",
    "MedInc\tHouseAge\tAveRooms\tAveBedrms\tPopulation\tAveOccup\tLatitude\tLongitude\n",
    "\n",
    "\n",
    "Der Datensatz enthält folgende Merkmale:\n",
    "- **MedInc:** Median des Einkommens im Bezirk\n",
    "- **HouseAge:** Median des Hausalters im Bezirk\n",
    "- **AveRooms:** durchschnittliche Anzahl der Zimmer pro Haushalt\n",
    "- **AveBedrms:** Durchschnittliche Anzahl der Schlafzimmer pro Haushalt\n",
    "- **Population:** Bezirkbevölkerung\n",
    "- **AveOccup:** durchschnittliche Anzahl der Haushaltsmitglieder\n",
    "- **Latitude:** Bezirk Breitengrad\n",
    "- **Longitude:** Bezirk Längengrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quellen:\n",
    "[1] Jake VanderPlas, [*Python Data Science Handbook*](https://jakevdp.github.io/PythonDataScienceHandbook), O'Reilly, 2016.\\\n",
    "[2] Wolf Riepl, [*Machine Learning mit R und caret: GBM optimieren (Gradient Boosting Machine)*](https://statistik-dresden.de/archives/14967), Artikel auf https://statistik-dresden.de,  Veröffentlicht am 23.01.2018 (zugegriffen am 27.04.2021)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
