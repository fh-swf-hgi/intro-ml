{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "befca7bb",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <IMG SRC=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/d5/Fachhochschule_Südwestfalen_20xx_logo.svg/320px-Fachhochschule_Südwestfalen_20xx_logo.svg.png\" WIDTH=250 ALIGN=\"right\">\n",
    "</figure>\n",
    "\n",
    "# Einführung Machine Learning\n",
    "### Sommersemester 2022\n",
    "Prof. Dr. Heiner Giefers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Aufgabe zur Logistischen Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aufgabe: Kreditbewertung\n",
    "\n",
    "Der Datensatz *Kreditscoring zur Klassifikation von Kreditnehmern. 2010. Open Data LMU. (https://doi.org/10.5282/ubm/data.23)* beinhaltet 1000 Datensätze, die Vergaben von Privatkrediten beschreiben.\n",
    "Die Spalten beschreiben verschiedene Merkmale, die die Art des Kredits sowie die Eigenschaften der Kunden beschreiben.\n",
    "Beispiele sind Höhe und Laufzeiten der Darlehn sowie das Alter und das Beschäftigungsverhältnis der Kreditnehmer.\n",
    "Die binäre Zielgröße (auch *Dummy Variable* genannt) bildet die Spalte `kredit`.\n",
    "Der Wert `1` bedeutet, dass für den entsprechenden Datenpunkt der Kredit zurückgezahlt wurde.\n",
    "Entsprechend bedeutet `kredit=0`, dass der Kredit nicht ordnungsgemäß zurückgezahlt wurde.\n",
    "\n",
    "Aufgrund dieser Datenbasis kann nun ein System entwickelt werden, dass für eine anstehende Kreditvergabe vorhersagt, ob der Kredit zurückgezalt wird."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Wir importieren zuerst die Pandas Bibliothek und laden den Datensatz `kredit.csv` in einen `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "url = \"https://github.com/fh-swf-hgi/intro-ml/raw/main/A06/kredit.csv\"\n",
    "\n",
    "dfile = \"./kredit.csv\"\n",
    "\n",
    "if not os.path.isfile(dfile):\n",
    "    urllib.request.urlretrieve(url, dfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"kredit.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Mit `df.info()` und `df.describe()` erhalten wir einige Informationen über den Datensatz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Wir teilen nun die kompletten Daten in einen Trainings- und einen Test-Datensatz auf.\n",
    "Dazu kann die Methode `train_test_split()` aus dem Modul `sklearn.model_selection` verwendet werden.\n",
    "Der Parameter `test_size` legt den Anteil des Daten im Test-Datensatz fest.\n",
    "Die Aufteilung der Datenpunkte erfolgt zufällig.\n",
    "Falls Sie immer die gleiche Aufteilung vornehmen wollen (damit die Ergebnisse vergleichbar sind) können Sie durch Festlegen des Parameters `random_state` erzwingen, dass immer die gleichen Folgen von Zufallszahlen erzeugt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:,1:],df.iloc[:,0],test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Wenn Sie testen wollen, wie gut das Modell mit einer Auswahl der Merkmale funktioniert, können Sie die Spalten im Datensatz entsprechend einschränken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "features = [\"laufkont\",\"rate\",\"moral\",\"buerge\",\"sparkont\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[features],df.iloc[:,0],test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe:** Bestimmen Sie folgende Werte:\n",
    "- m_train: Die Anzahl der Datenpunkte im Trainings-Datensatz\n",
    "- m_test: Die Anzahl der Datenpunkte im Test-Datensatz\n",
    "- X_dim: Die Anzahl der Attribute (unabhängige Variablen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-66b0371161ef375e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "m_train = None\n",
    "m_test = None\n",
    "X_dim = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-3b9b61c27a222471",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test Cell\n",
    "#----------\n",
    "\n",
    "assert m_train + m_test, X_dim == (df[features]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Für die Modellbildung verwenden wir nun wieder `sklearn`, diesmal mit einem logistischen Regressionsmodell.\n",
    "\n",
    "Die Modellparameter können über die Attribute `intercept_` und `coef_` abgerufen werden.\n",
    "Üblicherweise interessieren den Programmierer diese Werte nicht.\n",
    "die Schätzung für einen neuen Datenpunkt kann ja ganz einfach mit der Funktion `predict()` berechnet werden.\n",
    "Für uns sind die Informationen allerdings interessant, wenn wir die Methode `fit()` händisch nachprogrammieren wollen und so die jeweiligen gelerneten Modellparameter miteinander vergleichen können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "params = model.intercept_ +  model.coef_[0]\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Nachdem Wir das Modell mit den Trainingsdaten trainiert haben, verwenden wir den Testdatensatz um die Qualität des Modells zu bewerten.\n",
    "Eine Vorhersagegenauigkeit von 75% bedeutet, dass für 3 von 4 Krediten korrekt vorhergesagt werden konnte, ob ein Kredit vom Bankkunden ordnungsgemäß zurückgezahlt wurde.\n",
    "Die Interpretation des Ergebnisses, also die Einschätzung, ob die Vorhersagegenauigkeit gut oder schlecht ist, obliegt nun den Experten für das konkrete Anwendungsfeld, in diesem Fall den Kreditexperten der Bank.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_pred = model.predict(X_test)\n",
    "acc_train = np.sum((y_pred==y_test)*1)/len(y_test)\n",
    "print(\"Accuracy (Testdaten): %.2f%%\" % (acc_train*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe:** **Verwenden Sie die oben beschrieben Techniken, um Entscheidungsgrenzen für einen zufällig erzeugten Datensatz zu berechnen.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# generating two-class dataset\n",
    "X, y = make_blobs(n_samples=100, centers=2, n_features=2, center_box = (-5, 5))\n",
    "\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Spectral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a)** Teilen Sie den Datensatz auf (70% Training, 30% Test):\n",
    "- `X_train`: training dataset\n",
    "- `X_test`: test dataset\n",
    "- `y_train`: training labels\n",
    "- `y_test`: test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e7c0c8cf666d3b5c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = [None]*4\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-8818e07d53ed936b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test Cell\n",
    "#----------\n",
    "\n",
    "assert np.vstack((X_train, X_test)) in X and np.hstack((y_train, y_test)) in y\n",
    "assert y_train.size/y.size == 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)** Verwenden Sie die *sklearn*-Klasse `LogisticRegression` um ein Modell für den Datensatz zu bilden. Trainieren Sie das Modell mit den oben festgelegten Trainingsdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-12524a6611e42cf3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-c2da293e49378c98",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test Cell\n",
    "#----------\n",
    "\n",
    "assert type(logreg) == LogisticRegression\n",
    "assert logreg.intercept_, 'Trainieren Sie das Modell mit den Daten!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir visualisieren nun den Datensatz um darzustellen, wie gut unser Modell klassifiziert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting decision regions\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),np.arange(y_min, y_max, 0.01))\n",
    "\n",
    "Z = logreg.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "plt.contourf(xx, yy, Z, alpha=0.4, cmap=plt.cm.Spectral)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Spectral)\n",
    "plt.xlabel(r\"$\\Theta_0$\", fontsize=14)\n",
    "plt.ylabel(r\"$\\Theta_1$\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)** Testen Sie die Vorhersagegenauigkeit (*accuracy*) des Modells mit den Testdaten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6f17cc003e3def17",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "y_pred = None\n",
    "acc_test = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "print(\"accuracy: %.2f%%\" % acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-35985385625486b8",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test Cell\n",
    "#----------\n",
    "\n",
    "assert y_pred.shape == y_test.shape\n",
    "### BEGIN HIDDEN TEST\n",
    "assert acc_test == 100-np.sum(np.abs(y_pred-y_test))*100/len(y_pred)\n",
    "### END HIDDEN TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Multiklassen-Klassifikation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Die logistische Regression liefert uns Ergebnisse für binäre Zielvariablen.\n",
    "Oftmals wollen wir aber mehr als 2 Klassen unterscheiden.\n",
    "\n",
    "Eine Möglichkeit, um Multiklassen-Klassifikation mit logistischen Regression umzusetzen, ist die sogenannte *One-vs-all Klassifikation*.\n",
    "Dabei werden für `n` Klassen `n` separate, binäre Klassifikationsprobleme definiert, bei denen jeweils nur die betrachtete Klasse den Zielwert `1` zugeteilt bekommt, und für alle anderen Klassen der Zielwert `0` angenommen wird."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Scikit-Learn unterstüzt Multiklassen-Klassifikation in der Klasse `LogisticRegression` über den Parameter `multi_class`.\n",
    "Setzt man : `multi_class=\"ovr\"` führt die Funktion `fit` je eine logistische Regression für jedes Label nach dem *one-vs-all* (oder auch *one-vs-rest*, ovr) Prinzip aus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "In der folgenden Code-Zelle erzeugen wir 3 Punktwolken.\n",
    "Alle Punkte einer \"Wolke\" sollen zu einer bestimmten Klasse gehören."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame\n",
    "# generate 2d classification dataset\n",
    "X, y = make_blobs(n_samples=100, centers=3, n_features=2, random_state=10, cluster_std=2.5)\n",
    "# scatter plot, dots colored by class value\n",
    "df = DataFrame(dict(x=X[:,0], y=X[:,1], label=y))\n",
    "colors = {0:'red', 1:'blue', 2:'green'}\n",
    "markers = {0:'o', 1:'x', 2:'^'}\n",
    "fig, ax = plt.subplots()\n",
    "grouped = df.groupby('label')\n",
    "for key, group in grouped:\n",
    "    group.plot(ax=ax, kind='scatter', x='x', y='y', label=key, marker=markers[key], color=colors[key])\n",
    "    \n",
    "plt.legend(loc='upper right', prop={'size': 12})\n",
    "plt.savefig(\"LogistischeRegression20.png\",transparent=True, dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Nun wenden wir ein logistisches Regressionsmodell auf die Datenbasis an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3, random_state=0)\n",
    "\n",
    "model = LogisticRegression(solver='lbfgs',multi_class=\"ovr\")\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "model.intercept_ , model.coef_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Der folgende Graph zeigt die Entscheidungsgrenzen für das Klassifikationsmodell.\n",
    "Alle Punkte innerhalb eines Bereiches werden der jeweiligen Klasse zugeordnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "xx = np.linspace(X_train[:,0].min()-1, X_train[:,0].max()+1, 300)\n",
    "yy = np.linspace(X_train[:,1].min()-1, X_train[:,1].max()+1, 300)\n",
    "XX, YY = np.meshgrid(xx,yy)\n",
    "ZZ = model.predict(np.c_[XX.ravel(), YY.ravel()])\n",
    "ZZ = ZZ.reshape(XX.shape)\n",
    "\n",
    "yyy = model.intercept_[0] + model.coef_[0][0]*xx + model.coef_[0][1]*yy\n",
    "\n",
    "colors = {0:'red', 1:'blue', 2:'green'}\n",
    "markers = {0:'o', 1:'x', 2:'^'}\n",
    "fig, ax = plt.subplots()\n",
    "grouped = df.groupby('label')\n",
    "#plt.pcolormesh(XX, YY, ZZ, cmap=plt.cm.Set3)\n",
    "for key, group in grouped:\n",
    "    group.plot(ax=ax, kind='scatter', x='x', y='y', label=key, marker=markers[key], color=colors[key])\n",
    "    \n",
    "\n",
    "plt.contour(XX, YY, ZZ, cmap=plt.cm.Blues)\n",
    "plt.legend(loc='upper right', prop={'size': 12})\n",
    "plt.savefig(\"LogistischeRegression21.png\",transparent=True, dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
